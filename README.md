
markdown# ðŸ“„ Document Q&A API (RAG)

A production-ready RAG (Retrieval-Augmented Generation) system for document question-answering using FastAPI, LangChain, OpenAI, and ChromaDB.

## ðŸŽ¯ Features

- **Document Upload**: Support PDF, DOCX, TXT files
- **Intelligent Q&A**: Ask questions and get AI-powered answers from your documents
- **Vector Search**: Semantic search using ChromaDB and OpenAI embeddings
- **Source Citations**: Every answer includes relevant source chunks
- **Chat History**: Track all questions and answers
- **REST API**: Clean FastAPI endpoints with auto-documentation

## ðŸ—ï¸ Architecture
```
User Question â†’ Vectorize â†’ Search ChromaDB â†’ Retrieve Chunks â†’ 
Send to GPT with Context â†’ Generate Answer â†’ Return with Sources
```

## ðŸ“ Project Structure
```
document-qa/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                 # Core configurations
â”‚   â”‚   â”œâ”€â”€ config.py        # Settings
â”‚   â”‚   â””â”€â”€ logging.py       # Logging
â”‚   â”œâ”€â”€ database.py          # SQLAlchemy setup
â”‚   â”œâ”€â”€ vector_store/        # ChromaDB integration
â”‚   â”‚   â””â”€â”€ client.py
â”‚   â”œâ”€â”€ documents/           # Document management
â”‚   â”‚   â”œâ”€â”€ models.py        # DB models
â”‚   â”‚   â”œâ”€â”€ schemas.py       # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ router.py        # API endpoints
â”‚   â”‚   â””â”€â”€ service.py       # Business logic
â”‚   â”œâ”€â”€ chat/                # Q&A functionality
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ schemas.py
â”‚   â”‚   â”œâ”€â”€ router.py
â”‚   â”‚   â””â”€â”€ service.py       # RAG logic
â”‚   â””â”€â”€ main.py              # FastAPI app
â”œâ”€â”€ docker-compose.yml       # PostgreSQL
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env
```

## ðŸš€ Quick Start

### 1. Clone the repository
```bash
git clone https://github.com/YOUR_USERNAME/document-qa.git
cd document-qa
```

### 2. Create virtual environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Set up environment variables

Create `.env` file:
```bash
DATABASE_URL=postgresql://doc_user:doc_password@localhost:5432/doc_db
OPENAI_API_KEY=your-openai-api-key
DEBUG=True
```

### 5. Start PostgreSQL
```bash
docker-compose up -d
```

### 6. Run the API
```bash
python -m src.main
```

API will be available at: http://localhost:8000

Documentation: http://localhost:8000/docs

## ðŸ“ API Usage

### Upload a Document
```bash
curl -X POST "http://localhost:8000/api/v1/documents/upload" \
  -F "file=@document.pdf" \
  -F "title=My Document" \
  -F "description=Optional description"
```

### Ask a Question
```bash
curl -X POST "http://localhost:8000/api/v1/chat/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is the main topic?",
    "top_k": 3
  }'
```

**Response:**
```json
{
  "id": "...",
  "question": "What is the main topic?",
  "answer": "The main topic is...",
  "sources": [
    {
      "document_title": "My Document",
      "content": "...",
      "similarity_score": 0.89
    }
  ],
  "confidence": "high"
}
```

### Get Chat History
```bash
curl http://localhost:8000/api/v1/chat/history
```

### Get Stats
```bash
curl http://localhost:8000/api/v1/documents/stats
```

## ðŸ”§ Configuration

Edit `.env` to customize:
```bash
# OpenAI
OPENAI_API_KEY=your-key
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_CHAT_MODEL=gpt-3.5-turbo

# RAG Settings
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RESULTS=3

# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/db
```

## ðŸ› ï¸ Tech Stack

- **FastAPI** - Modern Python web framework
- **PostgreSQL** - Relational database for metadata
- **ChromaDB** - Vector database for semantic search
- **OpenAI** - Embeddings (text-embedding-3-small) + LLM (GPT-3.5/4)
- **LangChain** - LLM orchestration framework
- **SQLAlchemy** - Database ORM
- **Pydantic** - Data validation
- **Docker** - Containerization

## ðŸ“Š How RAG Works

1. **Document Processing**
   - Upload PDF/DOCX/TXT
   - Extract text
   - Split into chunks (1000 chars, 200 overlap)

2. **Vectorization**
   - Convert chunks to embeddings using OpenAI
   - Store in ChromaDB with metadata

3. **Query**
   - User asks question
   - Vectorize question
   - Find top-K similar chunks (semantic search)

4. **Answer Generation**
   - Send relevant chunks + question to GPT
   - GPT generates answer using only provided context
   - Return answer with source citations

## ðŸ§ª Testing

### Create test document
```bash
cat > test_doc.txt << 'EOF'
Employee Handbook

Section 1: Salary
Base salary: $80,000 per year
Payment: Bi-weekly

Section 2: Benefits
- Health insurance
- 15 days vacation
- 401k matching
EOF
```

### Upload and test
```bash
# Upload
curl -X POST "http://localhost:8000/api/v1/documents/upload" \
  -F "file=@test_doc.txt" \
  -F "title=Test Doc"

# Ask
curl -X POST "http://localhost:8000/api/v1/chat/ask" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is the salary?"}'
```

## ðŸš¦ Development

### Project was built with

- Python 3.9+
- FastAPI best practices
- Clean architecture (separation of concerns)
- Type hints throughout
- Structured logging

### Key learnings

- RAG implementation from scratch
- Vector database integration
- LLM prompt engineering
- Production-ready FastAPI structure

## ðŸ“ˆ Future Enhancements

- [ ] Authentication & authorization
- [ ] Multi-user support
- [ ] Advanced RAG (re-ranking, hybrid search)
- [ ] Frontend UI (React/Vue)
- [ ] Caching layer
- [ ] Model fine-tuning
- [ ] Monitoring & analytics
- [ ] Deploy to cloud (AWS/GCP/Azure)

## ðŸ› Troubleshooting

**Port already in use:**
```bash
lsof -ti:8000 | xargs kill -9
```

**Database connection error:**
```bash
docker-compose down -v
docker-compose up -d
```

**Module not found:**
```bash
python -m src.main  # Not: python src/main.py
```

## ðŸ“ License

MIT

## ðŸ‘¨â€ðŸ’» Author

Built as a learning project for RAG implementation and production FastAPI development.

## ðŸ™ Acknowledgments

- OpenAI for embeddings and LLM
- LangChain for RAG framework
- FastAPI community

---

**â­ Star this repo if you found it helpful!**
